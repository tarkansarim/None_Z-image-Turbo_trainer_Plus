from fastapi import APIRouter, HTTPException, WebSocket, WebSocketDisconnect
from typing import Dict, Any, Optional
import json
import re
import subprocess
import sys
import os
from datetime import datetime
from pathlib import Path

from core.config import CONFIGS_DIR, OUTPUT_BASE_DIR, MODEL_PATH, SaveConfigRequest, PROJECT_ROOT
from core import state
from core import job_service
from core.job_service import JobStatus

router = APIRouter(prefix="/api/training", tags=["training"])

# Track current job ID for progress updates
_current_job_id: Optional[str] = None

# Windows 兼容性：获取 subprocess 创建标志
def _get_subprocess_flags():
    """获取跨平台 subprocess 创建标志"""
    if os.name == 'nt':
        return subprocess.CREATE_NO_WINDOW
    return 0

def get_default_config():
    """Get default training configuration"""
    return {
        "name": "default",
        "acrf": {
            "turbo_steps": 10,
            "shift": 3.0,
            "jitter_scale": 0.02,
            # Min-SNR 加权参数（所有 loss 模式通用）
            "snr_gamma": 5.0,
            "snr_floor": 0.1
        },
        "network": {
            "dim": 16,
            "alpha": 16
        },
        "optimizer": {
            "type": "AdamW8bit"
        },
        "training": {
            "output_name": "zimage-lora",
            "learning_rate": 0.0001,
            "weight_decay": 0,
            "lr_scheduler": "constant",  # 少样本训练推荐 constant，cosine 需谨慎设置 warmup
            "lr_warmup_steps": 0,  # 默认不预热，少样本场景预热步数应 < 5% 总步数
            "lr_num_cycles": 1,
            # Standard 模式参数
            "lambda_fft": 0,
            "lambda_cosine": 0,
            # 损失模式
            "loss_mode": "standard",
            # 频域感知参数
            "alpha_hf": 1.0,
            "beta_lf": 0.2,
            # 风格结构参数
            "lambda_struct": 1.0,
            "lambda_light": 0.5,
            "lambda_color": 0.3,
            "lambda_tex": 0.5
        },
        "dataset": {
            "batch_size": 1,
            "shuffle": True,
            "enable_bucket": True,
            "datasets": []
        },
        "advanced": {
            "num_train_epochs": 10,
            "save_every_n_epochs": 1,
            "gradient_accumulation_steps": 4,
            "max_grad_norm": 1.0,
            "gradient_checkpointing": True,
            "mixed_precision": "bf16",
            "seed": 42,
            "resume": False,  # 恢复训练模式
            "multi_gpu": False,  # 多GPU训练
            "num_gpus": 0  # GPU数量 (0=自动检测)
        }
    }

@router.get("/system-paths")
async def get_system_paths():
    """Get system-wide model and output paths"""
    return {
        "model_path": MODEL_PATH,
        "output_base_dir": str(OUTPUT_BASE_DIR)
    }

@router.get("/defaults")
async def get_defaults():
    """Get default configuration for frontend store (flat structure)"""
    return {
        "modelPath": str(MODEL_PATH),
        "vaePath": str(MODEL_PATH / "vae"),
        "textEncoderPath": str(MODEL_PATH / "text_encoder"),
        "outputDir": str(OUTPUT_BASE_DIR),
        "outputName": "zimage-lora",
        "datasetConfigPath": "./dataset_config.toml",
        "cacheDir": "./cache",
        "epochs": 10,
        "batchSize": 1,
        "learningRate": 1e-4,
        "optimizer": "adamw",
        "scheduler": "cosine",
        "warmupSteps": 100,
        "networkDim": 64,
        "networkAlpha": 64,
        "mixedPrecision": "bf16",
        "gradientCheckpointing": True,
        "gradientAccumulationSteps": 1,
        "maxGradNorm": 1.0,
        "seed": 42
    }

@router.get("/configs")
async def list_training_configs():
    """List all saved training configurations"""
    try:
        configs = []
        if CONFIGS_DIR.exists():
            for config_file in CONFIGS_DIR.glob("*.json"):
                with open(config_file, "r", encoding="utf-8") as f:
                    config = json.load(f)
                    configs.append({
                        "name": config.get("name", config_file.stem),
                        "created": config.get("created", ""),
                        "modified": config.get("modified", "")
                    })
        return {"configs": configs}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to list configs: {str(e)}")

@router.get("/config/current")
async def get_current_config():
    """Get the most recently modified training configuration for preview"""
    try:
        if not CONFIGS_DIR.exists():
            return get_default_config()
        
        config_files = list(CONFIGS_DIR.glob("*.json"))
        if not config_files:
            return get_default_config()
        
        # 找最近修改的配置
        latest_file = max(config_files, key=lambda f: f.stat().st_mtime)
        
        with open(latest_file, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        return get_default_config()

@router.get("/config/{config_name}")
async def get_training_config(config_name: str):
    """Get a specific training configuration"""
    try:
        if config_name == "default":
            return get_default_config()
        
        config_path = CONFIGS_DIR / f"{config_name}.json"
        if not config_path.exists():
            return get_default_config()
        
        with open(config_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to load config: {str(e)}")

@router.post("/config/save")
async def save_training_config(request: SaveConfigRequest):
    """Save a training configuration"""
    try:
        safe_name = re.sub(r'[^\w\-]', '_', request.name)
        config_path = CONFIGS_DIR / f"{safe_name}.json"
        
        config_data = request.config
        config_data["name"] = safe_name
        now = datetime.now().isoformat()
        
        if config_path.exists():
            config_data["modified"] = now
            with open(config_path, "r", encoding="utf-8") as f:
                old_config = json.load(f)
                config_data["created"] = old_config.get("created", now)
        else:
            config_data["created"] = now
            config_data["modified"] = now
        
        with open(config_path, "w", encoding="utf-8") as f:
            json.dump(config_data, f, indent=2, ensure_ascii=False)
        
        return {"success": True, "name": safe_name, "path": str(config_path)}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to save config: {str(e)}")

@router.delete("/config/{config_name}")
async def delete_training_config(config_name: str):
    """Delete a training configuration"""
    try:
        if config_name == "default":
            raise HTTPException(status_code=400, detail="Cannot delete default config")
        
        config_path = CONFIGS_DIR / f"{config_name}.json"
        if not config_path.exists():
            raise HTTPException(status_code=404, detail="Config not found")
        
        config_path.unlink()
        return {"success": True, "message": f"Config '{config_name}' deleted"}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to delete config: {str(e)}")

@router.get("/presets")
async def get_training_presets():
    """Get preset training configurations"""
    presets = [
        {
            "name": "快速测试",
            "description": "小批次、少epoch、快速迭代",
            "config": {
                **get_default_config(),
                "name": "fast_test",
                "advanced": {
                    **get_default_config()["advanced"],
                    "num_train_epochs": 3,
                    "gradient_accumulation_steps": 2
                }
            }
        },
        {
            "name": "标准训练",
            "description": "平衡的训练配置",
            "config": {
                **get_default_config(),
                "name": "standard",
                "lora": {
                    "network_dim": 16,
                    "network_alpha": 8.0
                }
            }
        },
        {
            "name": "高质量",
            "description": "大Rank、长训练、高质量输出",
            "config": {
                **get_default_config(),
                "name": "high_quality",
                "lora": {
                    "network_dim": 32,
                    "network_alpha": 16.0
                },
                "training": {
                    **get_default_config()["training"],
                    "learning_rate": 0.00005
                },
                "advanced": {
                    **get_default_config()["advanced"],
                    "num_train_epochs": 20,
                    "gradient_accumulation_steps": 8
                }
            }
        }
    ]
    return {"presets": presets}

def check_dataset_cache(config: Dict[str, Any]) -> Dict[str, Any]:
    """检查数据集缓存状态（同步函数）"""
    dataset_cfg = config.get("dataset", {})
    datasets = dataset_cfg.get("datasets", [])
    
    if not datasets:
        # Return full dict structure even when no datasets (prevents KeyError)
        return {
            "has_cache": True, 
            "message": "No datasets configured",
            "total_images": 0,
            "latent_cached": 0,
            "text_cached": 0,
            "latent_missing": 0,
            "text_missing": 0
        }
    
    total_images = 0
    latent_cached = 0
    text_cached = 0
    
    image_extensions = {'.jpg', '.jpeg', '.png', '.webp', '.bmp'}
    
    for ds in datasets:
        cache_dir = ds.get("cache_directory", "")
        if not cache_dir:
            continue
        
        dataset_path = Path(cache_dir)
        if not dataset_path.exists():
            continue
        
        # 统计图片和缓存
        for f in dataset_path.rglob("*"):
            if f.is_file() and f.suffix.lower() in image_extensions:
                total_images += 1
                stem = f.stem
                parent = f.parent
                
                # 检查 latent 缓存
                if list(parent.glob(f"{stem}_*_zi.safetensors")):
                    latent_cached += 1
                
                # 检查 text 缓存 (格式: {name}_zi_te.safetensors)
                if list(parent.glob(f"{stem}_zi_te.safetensors")):
                    text_cached += 1
    
    has_cache = latent_cached > 0 and text_cached > 0
    
    return {
        "has_cache": has_cache,
        "total_images": total_images,
        "latent_cached": latent_cached,
        "text_cached": text_cached,
        "latent_missing": total_images - latent_cached,
        "text_missing": total_images - text_cached
    }


@router.post("/start")
async def start_training(config: Dict[str, Any], job_id: Optional[str] = None):
    """Start AC-RF training with accelerate launch
    
    如果缓存不完整，返回 needs_cache=True，前端应该先执行缓存
    
    Args:
        config: Training configuration
        job_id: Optional job ID to resume. If not provided, creates a new job.
    """
    global _current_job_id
    
    if state.training_process and state.training_process.poll() is None:
        raise HTTPException(status_code=400, detail="训练已在运行中")
    
    try:
        # 清空训练历史（新训练开始）
        state.clear_training_history()
        state.training_logs.clear()
        
        # 广播清空图表消息给前端
        from .websocket import manager
        import asyncio
        asyncio.create_task(manager.broadcast({
            "type": "training_reset",
            "training_history": state.get_training_history()  # 发送空的历史数据
        }))
        
        # === JOB TRACKING: Create or resume job ===
        output_name = config.get("training", {}).get("output_name", "zimage-lora")
        config_name = config.get("name", "default")
        
        if job_id:
            # Resuming existing job
            job = job_service.get_job(job_id)
            if job is None:
                raise HTTPException(status_code=404, detail="Job not found")
            _current_job_id = job_id
            state.add_log(f"恢复任务: {job['name']} (ID: {job_id[:8]}...)", "info")
        else:
            # Create new job
            job_id = job_service.create_job(
                name=output_name,
                config_name=config_name,
                config_data=config,
                output_dir=str(OUTPUT_BASE_DIR)
            )
            _current_job_id = job_id
            state.add_log(f"创建新任务: {output_name} (ID: {job_id[:8]}...)", "info")
        
        # 如果有生成模型加载，先卸载释放显存
        if state.pipeline is not None:
            state.add_log("检测到生成模型已加载，正在卸载以释放显存...", "info")
            import gc
            if state.current_lora_path:
                try:
                    state.pipeline.unload_lora_weights()
                except:
                    pass
                state.current_lora_path = None
            del state.pipeline
            state.pipeline = None
            gc.collect()
            import torch
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            state.add_log("生成模型已卸载", "info")
        
        # 检查缓存状态
        # Debug: Log datasets being checked
        datasets_to_check = config.get("dataset", {}).get("datasets", [])
        state.add_log(f"DEBUG: 检查 {len(datasets_to_check)} 个数据集的缓存状态", "info")
        for idx, ds in enumerate(datasets_to_check):
            state.add_log(f"DEBUG: Dataset {idx}: {ds.get('cache_directory', 'NO PATH')}", "info")
        
        cache_info = check_dataset_cache(config)
        state.add_log(f"DEBUG: cache_info = {cache_info}", "info")
        if not cache_info["has_cache"]:
            state.add_log(f"缓存不完整: Latent {cache_info['latent_cached']}/{cache_info['total_images']}, Text {cache_info['text_cached']}/{cache_info['total_images']}", "warning")
            return {
                "success": False,
                "needs_cache": True,
                "total_images": cache_info["total_images"],
                "latent_cached": cache_info["latent_cached"],
                "text_cached": cache_info["text_cached"],
                "latent_missing": cache_info["latent_missing"],
                "text_missing": cache_info["text_missing"],
                "message": f"缓存不完整，需要先生成缓存"
            }
        
        state.add_log(f"缓存检查通过: {cache_info['latent_cached']} latent, {cache_info['text_cached']} text", "info")
        
        # 生成 TOML 配置文件
        config_path = CONFIGS_DIR / "current_training.toml"
        toml_content = generate_acrf_toml_config(config)
        
        with open(config_path, "w", encoding="utf-8") as f:
            f.write(toml_content)
        
        state.add_log(f"AC-RF 配置已生成: {config_path}", "info")
        
        # 构建训练命令
        # 使用 scripts/train_acrf.py (AC-RF 训练脚本)
        python_exe = sys.executable
        train_script = PROJECT_ROOT / "scripts" / "train_acrf.py"
        
        mixed_precision = config.get("advanced", {}).get("mixed_precision", "bf16")
        multi_gpu = config.get("advanced", {}).get("multi_gpu", False)
        num_gpus = config.get("advanced", {}).get("num_gpus", 0)
        
        # 检测平台并选择分布式后端 (Windows: gloo, Linux: nccl)
        import platform
        distributed_backend = "gloo" if platform.system() == "Windows" else "nccl"
        
        if multi_gpu:
            state.add_log(f"多GPU训练模式 (backend: {distributed_backend})", "info")
            
            # Auto-detect GPU count if not specified
            if num_gpus == 0:
                import torch
                num_gpus = torch.cuda.device_count() if torch.cuda.is_available() else 1
                state.add_log(f"自动检测到 {num_gpus} 个GPU", "info")
            
            if platform.system() == "Windows":
                # Windows: use our custom launcher (Gloo + FileStore)
                # This bypasses accelerate launch which has issues with kubernetes.docker.internal
                multi_gpu_script = PROJECT_ROOT / "scripts" / "train_multi_gpu.py"
                cmd = [
                    python_exe,
                    str(multi_gpu_script),
                    "--config", str(config_path),
                    f"--num_gpus={num_gpus}",
                ]
            else:
                # Linux: use accelerate launch (NCCL + TCP) - optimal for Linux
                cmd = [
                    python_exe, "-m", "accelerate.commands.launch",
                    "--multi_gpu",
                    f"--num_processes={num_gpus}",
                    f"--mixed_precision={mixed_precision}",
                    str(train_script),
                    "--config", str(config_path),
                    "--distributed_backend", distributed_backend
                ]
        else:
            # Single GPU: run directly without accelerate launcher (more stable)
            cmd = [
                python_exe,
                str(train_script),
                "--config", str(config_path),
                "--distributed_backend", distributed_backend
            ]
        
        # 如果配置要求恢复训练
        if config.get("advanced", {}).get("resume", False):
            cmd.append("--resume")
            state.add_log("已启用恢复训练模式", "info")
        
        state.add_log(f"启动命令: {' '.join(cmd)}", "info")
        state.add_log(f"混合精度: {mixed_precision}", "info")
        
        # 启动训练进程
        env = os.environ.copy()
        env["PYTHONUNBUFFERED"] = "1"
        env["PYTHONPATH"] = str(PROJECT_ROOT / "src")  # Ensure src is in path
        
        # CRITICAL: Disable libuv for PyTorch distributed on Windows
        # Must be set for both parent and child processes
        env["USE_LIBUV"] = "0"
        env["TORCH_DISTRIBUTED_USE_LIBUV"] = "0"
        
        # Multi-GPU: Set CUDA_VISIBLE_DEVICES to use all GPUs
        if multi_gpu:
            import torch
            if torch.cuda.is_available():
                gpu_count = num_gpus if num_gpus > 0 else torch.cuda.device_count()
                # Create comma-separated list: "0,1,2,..." 
                env["CUDA_VISIBLE_DEVICES"] = ",".join(str(i) for i in range(gpu_count))
                state.add_log(f"CUDA_VISIBLE_DEVICES={env['CUDA_VISIBLE_DEVICES']}", "info")
            
            # Additional env vars for Windows multi-GPU stability
            env["NCCL_DEBUG"] = "WARN"
            env["TORCH_DISTRIBUTED_INIT_METHOD"] = "file"
        
        state.training_process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            cwd=str(PROJECT_ROOT),
            env=env,
            text=True,
            encoding='utf-8',
            errors='replace',
            bufsize=1,
            creationflags=_get_subprocess_flags()
        )
        
        state.add_log(f"AC-RF 训练进程已启动 (PID: {state.training_process.pid})", "success")
        
        # === JOB TRACKING: Update job status to running ===
        if _current_job_id:
            total_epochs = config.get("advanced", {}).get("num_train_epochs", 10)
            job_service.update_job_status(
                _current_job_id,
                JobStatus.RUNNING,
                total_epochs=total_epochs
            )
            job_service.save_job_log(_current_job_id, "info", f"Training started (PID: {state.training_process.pid})")
        
        return {
            "success": True,
            "message": "AC-RF 训练已启动",
            "pid": state.training_process.pid,
            "config_path": str(config_path),
            "job_id": _current_job_id
        }
        
    except Exception as e:
        state.add_log(f"启动失败: {str(e)}", "error")
        # === JOB TRACKING: Mark job as failed ===
        if _current_job_id:
            job_service.update_job_status(_current_job_id, JobStatus.FAILED, error_message=str(e))
        raise HTTPException(status_code=500, detail=f"启动训练失败: {str(e)}")


def generate_acrf_toml_config(config: Dict[str, Any]) -> str:
    """
    将前端配置转换为 AC-RF 训练 TOML 格式（包含 dataset 配置）
    
    匹配 scripts/train_acrf.py 的参数格式
    所有配置合并到一个 TOML 文件中
    """
    
    # 获取数据集配置
    dataset_cfg = config.get("dataset", {})
    datasets = dataset_cfg.get("datasets", [])
    
    toml_lines = [
        "# Z-Image AC-RF 训练配置 (自动生成)",
        f"# 生成时间: {datetime.now().isoformat()}",
        "",
        "[model]",
        f'dit = "{str(MODEL_PATH / "transformer").replace(chr(92), "/")}"',
        f'output_dir = "{str(OUTPUT_BASE_DIR).replace(chr(92), "/")}"',
        "",
        "[acrf]",
        f"turbo_steps = {config.get('acrf', {}).get('turbo_steps', 10)}",
        f"shift = {config.get('acrf', {}).get('shift', 3.0)}",
        f"jitter_scale = {config.get('acrf', {}).get('jitter_scale', 0.02)}",
        f"snr_gamma = {config.get('acrf', {}).get('snr_gamma', 5.0)}",
        f"snr_floor = {config.get('acrf', {}).get('snr_floor', 0.1)}",
        "",
        "[lora]",
        f"network_dim = {config.get('network', {}).get('dim', 8)}",
        f"network_alpha = {config.get('network', {}).get('alpha', 4.0)}",
        "",
        "[training]",
        f'output_name = "{config.get("training", {}).get("output_name", "zimage-lora")}"',
        f'optimizer_type = "{config.get("optimizer", {}).get("type", "AdamW8bit")}"',
        f"learning_rate = {config.get('training', {}).get('learning_rate', 0.0001)}",
        f"weight_decay = {config.get('training', {}).get('weight_decay', 0.01)}",
        f'lr_scheduler = "{config.get("training", {}).get("lr_scheduler", "constant")}"',
        f"lr_warmup_steps = {config.get('training', {}).get('lr_warmup_steps', 0)}",
        f"lr_num_cycles = {config.get('training', {}).get('lr_num_cycles', 1)}",
        # Standard 模式参数
        f"lambda_fft = {config.get('training', {}).get('lambda_fft', 0)}",
        f"lambda_cosine = {config.get('training', {}).get('lambda_cosine', 0)}",
        # 损失模式
        f'loss_mode = "{config.get("training", {}).get("loss_mode", "standard")}"',
        # === CUSTOM: Loss scope (global vs per_dataset) ===
        f'loss_scope = "{config.get("training", {}).get("loss_scope", "global")}"',
        # 频域感知参数
        f"alpha_hf = {config.get('training', {}).get('alpha_hf', 1.0)}",
        f"beta_lf = {config.get('training', {}).get('beta_lf', 0.2)}",
        # 风格结构参数 (used when loss_scope = "global")
        f"lambda_struct = {config.get('training', {}).get('lambda_struct', 1.0)}",
        f"lambda_light = {config.get('training', {}).get('lambda_light', 0.5)}",
        f"lambda_color = {config.get('training', {}).get('lambda_color', 0.3)}",
        f"lambda_tex = {config.get('training', {}).get('lambda_tex', 0.5)}",
        f"num_train_epochs = {config.get('advanced', {}).get('num_train_epochs', 10)}",
        f"save_every_n_epochs = {config.get('advanced', {}).get('save_every_n_epochs', 1)}",
        f"gradient_accumulation_steps = {config.get('advanced', {}).get('gradient_accumulation_steps', 4)}",
        f'mixed_precision = "{config.get("advanced", {}).get("mixed_precision", "bf16")}"',
        f"seed = {config.get('advanced', {}).get('seed', 42)}",
        "",
        "[advanced]",
        f"max_grad_norm = {config.get('advanced', {}).get('max_grad_norm', 1.0)}",
        f"gradient_checkpointing = {'true' if config.get('advanced', {}).get('gradient_checkpointing', True) else 'false'}",
        "",
        "[optimization]",
        "auto_optimize = true",
        "",
        "# ============ Dataset 配置 ============",
        "[dataset]",
        f"batch_size = {dataset_cfg.get('batch_size', 1)}",
        f"shuffle = {'true' if dataset_cfg.get('shuffle', True) else 'false'}",
        f"enable_bucket = {'true' if dataset_cfg.get('enable_bucket', True) else 'false'}",
        "",
    ]
    
    # 添加数据集源（带完整配置）
    loss_scope = config.get("training", {}).get("loss_scope", "global")
    loss_mode = config.get("training", {}).get("loss_mode", "standard")
    for ds in datasets:
        cache_dir = ds.get("cache_directory", "")
        if cache_dir:
            ds_lines = [
                "[[dataset.sources]]",
                f'cache_directory = "{cache_dir.replace(chr(92), "/")}"',
                f"num_repeats = {ds.get('num_repeats', 1)}",
                f"resolution_limit = {ds.get('resolution_limit', 1024)}",
            ]
            # === CUSTOM: Include per-dataset loss weights when loss_scope = "per_dataset" ===
            if loss_scope == "per_dataset":
                # Standard mode params
                if loss_mode == "standard":
                    ds_lines.extend([
                        f"lambda_fft = {ds.get('lambda_fft', 0.0)}",
                        f"lambda_cosine = {ds.get('lambda_cosine', 0.0)}",
                    ])
                # Frequency mode params
                if loss_mode in ["frequency", "unified"]:
                    ds_lines.extend([
                        f"alpha_hf = {ds.get('alpha_hf', 1.0)}",
                        f"beta_lf = {ds.get('beta_lf', 0.2)}",
                    ])
                # Style mode params
                if loss_mode in ["style", "unified"]:
                    ds_lines.extend([
                        f"lambda_struct = {ds.get('lambda_struct', 1.0)}",
                        f"lambda_light = {ds.get('lambda_light', 0.0)}",
                        f"lambda_color = {ds.get('lambda_color', 0.0)}",
                        f"lambda_tex = {ds.get('lambda_tex', 0.0)}",
                    ])
            ds_lines.append("")
            toml_lines.extend(ds_lines)
    
    return "\n".join(toml_lines)


@router.post("/stop")
async def stop_training():
    """Stop training process with proper cleanup (including child processes)"""
    global _current_job_id
    
    if state.training_process:
        pid = state.training_process.pid
        state.add_log(f"正在停止训练进程 (PID: {pid})...", "warning")
        
        # === CUSTOM: Kill all child processes (multi-GPU workers) ===
        try:
            import psutil
            parent = psutil.Process(pid)
            children = parent.children(recursive=True)
            
            # Kill children first
            for child in children:
                try:
                    state.add_log(f"终止子进程 (PID: {child.pid})...", "info")
                    child.terminate()
                except psutil.NoSuchProcess:
                    pass
            
            # Wait for children to terminate
            gone, alive = psutil.wait_procs(children, timeout=5)
            for p in alive:
                try:
                    p.kill()
                except psutil.NoSuchProcess:
                    pass
                    
        except ImportError:
            state.add_log("psutil not installed, using basic termination", "warning")
        except psutil.NoSuchProcess:
            pass
        except Exception as e:
            state.add_log(f"清理子进程时出错: {e}", "warning")
        
        # Now terminate the parent
        state.training_process.terminate()
        
        # 等待进程结束（最多10秒）
        try:
            state.training_process.wait(timeout=10)
        except subprocess.TimeoutExpired:
            # 强制杀死
            state.training_process.kill()
            state.training_process.wait(timeout=5)
            state.add_log("进程被强制终止", "warning")
        
        state.training_process = None
        state.add_log("训练已停止，显存将被释放", "warning")
        
        # === JOB TRACKING: Update job status to stopped ===
        if _current_job_id:
            # Get current progress from state for checkpoint info
            history = state.get_training_history()
            job_service.update_job_status(
                _current_job_id,
                JobStatus.STOPPED,
                current_epoch=history.get("current_epoch", 0),
                current_step=history.get("current_step", 0),
                final_loss=history.get("loss", None)
            )
            job_service.save_job_log(_current_job_id, "warning", "Training stopped by user")
            _current_job_id = None
        
        # 清理 Python 端的缓存
        import gc
        gc.collect()
        
        # === CUSTOM: Force CUDA cache clear ===
        try:
            import torch
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                state.add_log("CUDA缓存已清理", "info")
        except:
            pass
        
    return {"status": "stopped"}

@router.get("/status")
async def get_training_status():
    """Get current training status"""
    is_running = state.training_process is not None and state.training_process.poll() is None
    return {
        "running": is_running,
        "pid": state.training_process.pid if state.training_process else None,
        "job_id": _current_job_id
    }


@router.post("/jobs/{job_id}/resume")
async def resume_job(job_id: str):
    """Resume a stopped job."""
    global _current_job_id
    
    if state.training_process and state.training_process.poll() is None:
        raise HTTPException(status_code=400, detail="训练已在运行中")
    
    # Get job
    job = job_service.get_job(job_id)
    if job is None:
        raise HTTPException(status_code=404, detail="Job not found")
    
    # Check status
    if job["status"] not in [JobStatus.PENDING, JobStatus.STOPPED, JobStatus.FAILED]:
        raise HTTPException(status_code=400, detail=f"Cannot resume job with status: {job['status']}")
    
    # Get config snapshot
    config = job.get("config_snapshot")
    if not config:
        raise HTTPException(status_code=400, detail="Job has no saved configuration")
    
    # Enable resume mode
    if "advanced" not in config:
        config["advanced"] = {}
    config["advanced"]["resume"] = True
    
    # Start training with this config and job_id
    return await start_training(config, job_id=job_id)


@router.post("/jobs/{job_id}/stop")
async def stop_job(job_id: str):
    """Stop a specific job (alias for stop_training with job context)."""
    global _current_job_id
    
    if _current_job_id != job_id:
        raise HTTPException(status_code=400, detail="This job is not currently running")
    
    return await stop_training()


def update_current_job_progress(
    current_epoch: int,
    current_step: int,
    total_steps: int,
    loss: Optional[float] = None,
    lr: Optional[float] = None
) -> None:
    """
    Update progress for the currently running job.
    Called from websocket handler when parsing training output.
    """
    global _current_job_id
    
    if _current_job_id:
        job_service.update_job_progress(
            _current_job_id,
            current_epoch=current_epoch,
            current_step=current_step,
            total_steps=total_steps,
            loss=loss,
            lr=lr
        )


def mark_current_job_completed(lora_path: Optional[str] = None, final_loss: Optional[float] = None) -> None:
    """
    Mark the current job as completed.
    Called when training finishes successfully.
    """
    global _current_job_id
    
    if _current_job_id:
        job_service.update_job_status(
            _current_job_id,
            JobStatus.COMPLETED,
            lora_path=lora_path,
            final_loss=final_loss
        )
        job_service.save_job_log(_current_job_id, "success", "Training completed successfully")
        _current_job_id = None


def mark_current_job_failed(error_message: str) -> None:
    """
    Mark the current job as failed.
    Called when training fails with an error.
    """
    global _current_job_id
    
    if _current_job_id:
        job_service.update_job_status(
            _current_job_id,
            JobStatus.FAILED,
            error_message=error_message
        )
        job_service.save_job_log(_current_job_id, "error", f"Training failed: {error_message}")
        _current_job_id = None


def get_current_job_id() -> Optional[str]:
    """Get the current job ID."""
    return _current_job_id

@router.get("/logs")
async def get_logs():
    """Get training logs"""
    return {"logs": state.training_logs[-100:]}


@router.websocket("/ws")
async def training_websocket(websocket: WebSocket):
    """WebSocket endpoint for real-time training updates"""
    await websocket.accept()
    state.training_websockets.append(websocket)
    
    try:
        # 发送当前状态
        is_running = state.training_process is not None and state.training_process.poll() is None
        await websocket.send_json({
            "type": "status",
            "payload": {"running": is_running}
        })
        
        # 发送历史日志
        for log in state.training_logs[-50:]:
            await websocket.send_json({
                "type": "log",
                "payload": log
            })
        
        # 保持连接，等待消息或断开
        while True:
            try:
                # 读取训练进程输出（如果正在运行）
                if state.training_process and state.training_process.poll() is None:
                    if state.training_process.stdout:
                        line = state.training_process.stdout.readline()
                        if line:
                            state.add_log(line.strip(), "info")
                            await websocket.send_json({
                                "type": "log",
                                "payload": {"message": line.strip(), "level": "info"}
                            })
                
                # 检查训练是否完成
                if state.training_process and state.training_process.poll() is not None:
                    exit_code = state.training_process.poll()
                    if exit_code == 0:
                        await websocket.send_json({"type": "complete", "payload": {}})
                    else:
                        await websocket.send_json({
                            "type": "error",
                            "payload": {"message": f"训练进程退出，代码: {exit_code}"}
                        })
                    state.training_process = None
                
                # 等待客户端消息（带超时）
                import asyncio
                try:
                    data = await asyncio.wait_for(websocket.receive_text(), timeout=1.0)
                    # 处理客户端消息（如心跳）
                    if data == "ping":
                        await websocket.send_text("pong")
                except asyncio.TimeoutError:
                    pass  # 超时继续循环
                    
            except WebSocketDisconnect:
                break
                
    except Exception as e:
        state.add_log(f"WebSocket 错误: {str(e)}", "error")
    finally:
        if websocket in state.training_websockets:
            state.training_websockets.remove(websocket)
