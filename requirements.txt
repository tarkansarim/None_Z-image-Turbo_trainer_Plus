# ============================================================================
# None Trainer - Z-Image Turbo LoRA 训练依赖
# ============================================================================
# 
# ⚠️ 重要提示：
# 1. PyTorch 需要手动安装（根据 CUDA 版本选择）
# 2. Flash Attention 需要手动安装预编译 whl
# 3. 详见 README.md 安装说明
#
# ============================================================================

# ========================
# Core - 核心依赖
# ========================
numpy>=1.24.0
Pillow>=10.0.0
scipy>=1.10.0

# ========================
# PyTorch 生态（手动安装）
# ========================
# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
torch>=2.1.0
torchvision>=0.16.0
torchaudio>=2.1.0

# ========================
# Diffusers & Transformers
# ========================
# diffusers 建议从 git 安装最新版：
# pip install git+https://github.com/huggingface/diffusers.git
#diffusers>=0.36.0
transformers>=4.40.0
accelerate>=0.27.0
safetensors>=0.4.0
peft>=0.10.0  # LoRA 加载必需

# ========================
# 优化器
# ========================
bitsandbytes>=0.42.0  # AdamW8bit 优化器

# ========================
# 损失函数
# ========================
lpips>=0.1.4  # 感知损失（可选）

# ========================
# 配置解析
# ========================
toml>=0.10.0
tomli>=2.0.0
PyYAML>=6.0.0

# ========================
# Web UI & API
# ========================
fastapi>=0.110.0
uvicorn[standard]>=0.27.0
pydantic>=2.5.0
websockets>=12.0
python-multipart>=0.0.6
python-dotenv>=1.0.0
aiofiles>=23.0.0

# ========================
# HTTP 客户端
# ========================
requests>=2.31.0
httpx>=0.26.0

# ========================
# 模型下载（魔搭 ModelScope）
# ========================
modelscope>=1.10.0

# ========================
# 进度条 & 日志
# ========================
tqdm>=4.66.0
rich>=13.0.0

# ========================
# 工具
# ========================
einops>=0.7.0  # Flash Attention 依赖
packaging>=23.0

# ============================================================================
# 可选依赖（按需安装）
# ============================================================================
# 
# Flash Attention 2（推荐，需要手动安装预编译 whl）:
#   下载地址: https://github.com/Dao-AILab/flash-attention/releases
#   pip install flash_attn-xxx.whl
#
# Prodigy 优化器（实验性）:
#   pip install prodigyopt
#
# ============================================================================
