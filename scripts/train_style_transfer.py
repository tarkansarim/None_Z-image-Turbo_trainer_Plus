"""
[START] Style-Structure Transfer Training Script for Z-Image-Turbo

ç»“æ„é”é£æ ¼è¿ç§»è®­ç»ƒè„šæœ¬

æ ¸å¿ƒåŠŸèƒ½ï¼š
è¾“å…¥ä¸€å¼ æ™®é€šç”»è´¨å›¾ç‰‡ï¼Œè¾“å‡ºä¸€å¼ ä¿æŒåŸå›¾å‡ ä½•ç»“æ„ï¼ˆStructure-Preservingï¼‰ï¼Œ
ä½†å…·æœ‰"å¤§å¸ˆçº§"å…‰å½±ã€è‰²è°ƒå’Œçº¹ç†è´¨æ„Ÿçš„å›¾ç‰‡ã€‚

æŠ€æœ¯è·¯å¾„ï¼š
- å›¾ç”Ÿå›¾æ¨¡å¼è®­ç»ƒ (Img2Img Training)
- è‡ªç›‘ç£é€€åŒ–ç­–ç•¥ (Self-Supervised Degradation)
- é¢‘åŸŸåˆ†ç¦»æŸå¤± (Style-Structure Loss)

Loss æ¶æ„ï¼š
L_total = Î»_struct * L_SSIM + Î»_light * L_Moments_L + Î»_color * L_Moments_ab + Î»_tex * L_HighFreq

Usage:
    python scripts/train_style_transfer.py --config config/style_transfer_config.toml
"""

import os
import sys
import math
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "../src"))

import torch
import argparse
from pathlib import Path
from tqdm import tqdm
from accelerate import Accelerator
from accelerate.utils import set_seed

from zimage_trainer.acrf_trainer import ACRFTrainer
from zimage_trainer.utils.zimage_utils import load_transformer
from zimage_trainer.networks.lora import LoRANetwork
from zimage_trainer.dataset.dataloader import create_dataloader
from zimage_trainer.utils.memory_optimizer import MemoryOptimizer
from zimage_trainer.utils.hardware_detector import HardwareDetector
from zimage_trainer.losses.style_structure_loss import LatentStyleStructureLoss
from zimage_trainer.utils.degradation import ImageDegradation, create_degradation_transform

import logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def parse_args():
    parser = argparse.ArgumentParser(description="Style-Structure Transfer è®­ç»ƒè„šæœ¬")
    
    # é…ç½®æ–‡ä»¶å‚æ•°
    parser.add_argument("--config", type=str, help="è¶…å‚æ•°é…ç½®æ–‡ä»¶è·¯å¾„ (.toml)")
    
    # æ¨¡å‹è·¯å¾„
    parser.add_argument("--dit", type=str, help="Transformer æ¨¡å‹è·¯å¾„")
    parser.add_argument("--dataset_config", type=str, help="æ•°æ®é›†é…ç½®æ–‡ä»¶")
    parser.add_argument("--output_dir", type=str, default="output/style_transfer", help="è¾“å‡ºç›®å½•")
    
    # AC-RF å‚æ•°
    parser.add_argument("--turbo_steps", type=int, default=10, help="Turbo æ­¥æ•°")
    parser.add_argument("--shift", type=float, default=3.0, help="æ—¶é—´æ­¥ shift å‚æ•°")
    parser.add_argument("--jitter_scale", type=float, default=0.02, help="é”šç‚¹æŠ–åŠ¨å¹…åº¦")
    
    # LoRA å‚æ•°
    parser.add_argument("--network_dim", type=int, default=32, help="LoRA rank (é£æ ¼è¿ç§»å»ºè®® 32-128)")
    parser.add_argument("--network_alpha", type=float, default=16.0, help="LoRA alpha")
    
    # é£æ ¼ç»“æ„ Loss å‚æ•°
    parser.add_argument("--lambda_struct", type=float, default=1.0, 
                       help="ç»“æ„é”æƒé‡ (SSIMï¼Œé˜²æ­¢è„¸å´©)")
    parser.add_argument("--lambda_light", type=float, default=0.5, 
                       help="å…‰å½±å­¦ä¹ æƒé‡ (Lé€šé“ç»Ÿè®¡)")
    parser.add_argument("--lambda_color", type=float, default=0.3, 
                       help="è‰²è°ƒè¿ç§»æƒé‡ (abé€šé“ç»Ÿè®¡)")
    parser.add_argument("--lambda_tex", type=float, default=0.5, 
                       help="è´¨æ„Ÿå¢å¼ºæƒé‡ (é«˜é¢‘L1)")
    parser.add_argument("--lambda_base", type=float, default=1.0, 
                       help="åŸºç¡€ v-prediction loss æƒé‡")
    
    # é€€åŒ–å‚æ•°
    parser.add_argument("--degradation_strength", type=str, default="medium",
                       choices=["light", "medium", "heavy"],
                       help="é€€åŒ–å¼ºåº¦é¢„è®¾")
    parser.add_argument("--enable_degradation", action="store_true", default=True,
                       help="å¯ç”¨è‡ªç›‘ç£é€€åŒ–ï¼ˆå›¾ç”Ÿå›¾è®­ç»ƒï¼‰")
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument("--optimizer_type", type=str, default="AdamW", 
                       choices=["AdamW", "AdamW8bit", "Adafactor"])
    parser.add_argument("--learning_rate", type=float, default=1e-4, help="å­¦ä¹ ç‡")
    parser.add_argument("--weight_decay", type=float, default=1e-2, help="æƒé‡è¡°å‡")
    
    # LR Scheduler å‚æ•°
    parser.add_argument("--lr_scheduler", type=str, default="cosine", 
        choices=["linear", "cosine", "cosine_with_restarts", "polynomial", "constant", "constant_with_warmup"])
    parser.add_argument("--lr_warmup_steps", type=int, default=100, help="Warmup æ­¥æ•°")
    parser.add_argument("--lr_num_cycles", type=int, default=1)
    
    # è®­ç»ƒæ§åˆ¶
    parser.add_argument("--num_train_epochs", type=int, default=10, help="è®­ç»ƒ Epoch æ•°")
    parser.add_argument("--save_every_n_epochs", type=int, default=1, help="ä¿å­˜é—´éš”")
    parser.add_argument("--output_name", type=str, default="zimage-style-lora", help="è¾“å‡ºæ–‡ä»¶å")
    
    # é€šç”¨å‚æ•°
    parser.add_argument("--gradient_accumulation_steps", type=int, default=1)
    parser.add_argument("--mixed_precision", type=str, default="bf16", choices=["no", "fp16", "bf16"])
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--max_grad_norm", type=float, default=1.0)
    parser.add_argument("--gradient_checkpointing", action="store_true")
    
    args = parser.parse_args()
    
    # è¯»å–é…ç½®æ–‡ä»¶
    if args.config:
        try:
            import tomli
        except ImportError:
            import tomllib as tomli
            
        with open(args.config, "rb") as f:
            config = tomli.load(f)
        
        defaults = {}
        for section in config.values():
            if isinstance(section, dict):
                defaults.update(section)
            
        parser.set_defaults(**defaults)
        args = parser.parse_args()
        
    if not args.dit:
        parser.error("--dit is required")
    
    if not args.dataset_config and args.config:
        args.dataset_config = args.config
        
    return args


def main():
    args = parse_args()
    
    # ç¡¬ä»¶æ£€æµ‹
    logger.info("[DETECT] æ­£åœ¨è¿›è¡Œç¡¬ä»¶æ£€æµ‹...")
    hardware_detector = HardwareDetector()
    hardware_detector.print_detection_summary()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    # åˆå§‹åŒ– Accelerator
    accelerator = Accelerator(
        gradient_accumulation_steps=args.gradient_accumulation_steps,
        mixed_precision=args.mixed_precision,
    )
    
    # è®¾ç½®éšæœºç§å­
    if args.seed is not None:
        set_seed(args.seed)
    
    logger.info("="*60)
    logger.info("[START] å¯åŠ¨ Style-Structure Transfer è®­ç»ƒ")
    logger.info("="*60)
    logger.info(f"ğŸ¨ è®­ç»ƒç­–ç•¥: ç»“æ„é”é£æ ¼è¿ç§»")
    logger.info(f"   ç»“æ„é” (SSIM): {args.lambda_struct}")
    logger.info(f"   å…‰å½±å­¦ä¹ : {args.lambda_light}")
    logger.info(f"   è‰²è°ƒè¿ç§»: {args.lambda_color}")
    logger.info(f"   è´¨æ„Ÿå¢å¼º: {args.lambda_tex}")
    logger.info(f"   é€€åŒ–å¼ºåº¦: {args.degradation_strength}")
    logger.info(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    logger.info(f"LoRA rank: {args.network_dim}")
    
    # 1. åŠ è½½æ¨¡å‹
    logger.info("\n[LOAD] åŠ è½½ Transformer...")
    weight_dtype = torch.float32
    if accelerator.mixed_precision == "fp16":
        weight_dtype = torch.float16
    elif accelerator.mixed_precision == "bf16":
        weight_dtype = torch.bfloat16
    
    transformer = load_transformer(
        transformer_path=args.dit,
        device=accelerator.device,
        torch_dtype=weight_dtype,
    )
    transformer.requires_grad_(False)
    transformer.train()
    
    if args.gradient_checkpointing:
        transformer.enable_gradient_checkpointing()
        logger.info("  [OK] æ¢¯åº¦æ£€æŸ¥ç‚¹å·²å¯ç”¨")
    
    # 2. åˆ›å»º LoRA ç½‘ç»œ
    logger.info(f"\n[SETUP] åˆ›å»º LoRA ç½‘ç»œ (rank={args.network_dim})...")
    network = LoRANetwork(
        unet=transformer,
        lora_dim=args.network_dim,
        alpha=args.network_alpha,
        multiplier=1.0,
    )
    network.apply_to(transformer)
    
    trainable_params = []
    for lora_module in network.lora_modules.values():
        trainable_params.extend(lora_module.get_trainable_params())
    
    lora_param_count = sum(p.numel() for p in trainable_params)
    logger.info(f"LoRA å¯è®­ç»ƒå‚æ•°: {lora_param_count:,} ({lora_param_count/1e6:.2f}M)")
    
    # 3. åˆ›å»º AC-RF Trainer
    logger.info(f"\n[INIT] åˆå§‹åŒ– AC-RF Trainer...")
    acrf_trainer = ACRFTrainer(
        num_train_timesteps=1000,
        turbo_steps=args.turbo_steps,
        shift=args.shift,
    )
    acrf_trainer.verify_setup()
    
    # 4. åˆ›å»ºé£æ ¼ç»“æ„ Loss
    logger.info(f"\n[LOSS] åˆå§‹åŒ– Style-Structure Loss...")
    loss_fn = LatentStyleStructureLoss(
        lambda_struct=args.lambda_struct,
        lambda_light=args.lambda_light,
        lambda_color=args.lambda_color,
        lambda_tex=args.lambda_tex,
        lambda_base=args.lambda_base,
    )
    
    # 5. åˆ›å»ºé€€åŒ–å˜æ¢
    if args.enable_degradation:
        logger.info(f"\n[DEGRADE] åˆå§‹åŒ–é€€åŒ–å˜æ¢ (å¼ºåº¦: {args.degradation_strength})...")
        degradation = create_degradation_transform(args.degradation_strength)
    else:
        degradation = None
        logger.info("[DEGRADE] é€€åŒ–å˜æ¢å·²ç¦ç”¨")
    
    # 6. åˆ›å»ºæ•°æ®åŠ è½½å™¨
    logger.info("\n[DATA] åŠ è½½æ•°æ®é›†...")
    dataloader = create_dataloader(args)
    logger.info(f"æ•°æ®é›†å¤§å°: {len(dataloader)} batches")
    
    # 7. è®¡ç®—è®­ç»ƒæ­¥æ•°
    num_update_steps_per_epoch = math.ceil(len(dataloader) / args.gradient_accumulation_steps)
    args.max_train_steps = args.num_train_epochs * num_update_steps_per_epoch
    
    logger.info(f"  Num Epochs = {args.num_train_epochs}")
    logger.info(f"  Total Optimization Steps = {args.max_train_steps}")
    
    print(f"[TRAINING_INFO] total_steps={args.max_train_steps} total_epochs={args.num_train_epochs}", flush=True)

    # 8. åˆ›å»ºä¼˜åŒ–å™¨
    logger.info(f"\n[SETUP] åˆå§‹åŒ–ä¼˜åŒ–å™¨: {args.optimizer_type}")
    
    if args.optimizer_type == "AdamW":
        optimizer = torch.optim.AdamW(
            trainable_params, 
            lr=args.learning_rate,
            weight_decay=args.weight_decay
        )
    elif args.optimizer_type == "AdamW8bit":
        try:
            import bitsandbytes as bnb
            optimizer = bnb.optim.AdamW8bit(
                trainable_params, 
                lr=args.learning_rate,
                weight_decay=args.weight_decay
            )
        except ImportError:
            optimizer = torch.optim.AdamW(trainable_params, lr=args.learning_rate, weight_decay=args.weight_decay)
    elif args.optimizer_type == "Adafactor":
        from transformers.optimization import Adafactor
        optimizer = Adafactor(trainable_params, lr=args.learning_rate, weight_decay=args.weight_decay)
        
    # 9. åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨
    from diffusers.optimization import get_scheduler
    logger.info(f"[SCHED] åˆå§‹åŒ–è°ƒåº¦å™¨: {args.lr_scheduler} (warmup={args.lr_warmup_steps})")
    lr_scheduler = get_scheduler(
        args.lr_scheduler,
        optimizer=optimizer,
        num_warmup_steps=args.lr_warmup_steps,
        num_training_steps=args.max_train_steps,
        num_cycles=args.lr_num_cycles,
    )
    
    # 10. Accelerator prepare
    transformer, network, optimizer, dataloader, lr_scheduler = accelerator.prepare(
        transformer, network, optimizer, dataloader, lr_scheduler
    )
    
    # 11. å†…å­˜ä¼˜åŒ–å™¨
    memory_optimizer = MemoryOptimizer({'block_swap_enabled': False})
    memory_optimizer.start()
    
    # 12. è®­ç»ƒå¾ªç¯
    logger.info("\n" + "="*60)
    logger.info("[TARGET] å¼€å§‹ç»“æ„é”é£æ ¼è¿ç§»è®­ç»ƒ")
    logger.info("="*60)
    
    global_step = 0
    progress_bar = tqdm(total=args.max_train_steps, desc="Style-Transfer Training", disable=True)
    
    # EMA å¹³æ»‘ loss
    ema_loss = None
    ema_decay = 0.99
    
    for epoch in range(args.num_train_epochs):
        logger.info(f"\nEpoch {epoch + 1}/{args.num_train_epochs}")
        transformer.train()
        
        for step, batch in enumerate(dataloader):
            with accelerator.accumulate(network):
                # è·å–æ•°æ® (é«˜è´¨é‡ç›®æ ‡)
                latents = batch['latents'].to(accelerator.device, dtype=weight_dtype)
                vl_embed = batch['vl_embed']
                
                if isinstance(vl_embed, list):
                    vl_embed = [tensor.to(accelerator.device, dtype=weight_dtype) for tensor in vl_embed]
                else:
                    vl_embed = vl_embed.to(accelerator.device, dtype=weight_dtype)
                
                # ç”Ÿæˆå™ªå£°
                noise = torch.randn_like(latents)
                
                # å¯¹äºé£æ ¼è¿ç§»è®­ç»ƒï¼Œæˆ‘ä»¬ä½¿ç”¨åŸå§‹ latents ä½œä¸ºç›®æ ‡
                # ä½†å¯ä»¥å¯¹è¾“å…¥åº”ç”¨é€€åŒ–ï¼ˆåœ¨ latent ç©ºé—´è¿‘ä¼¼ï¼‰
                target_latents = latents
                
                # AC-RF é‡‡æ ·ï¼ˆä½¿ç”¨ç›®æ ‡ latentsï¼‰
                noisy_latents, timesteps, target_velocity = acrf_trainer.sample_batch(
                    target_latents, noise, jitter_scale=args.jitter_scale
                )
                
                # å‡†å¤‡æ¨¡å‹è¾“å…¥
                model_input = noisy_latents.unsqueeze(2)
                model_input_list = list(model_input.unbind(dim=0))
                
                # Timestep normalization
                timesteps_normalized = (1000 - timesteps) / 1000.0
                timesteps_normalized = timesteps_normalized.to(dtype=weight_dtype)
                
                # å‰å‘ä¼ æ’­
                model_pred_list = transformer(
                    x=model_input_list,
                    t=timesteps_normalized,
                    cap_feats=vl_embed,
                )[0]
                
                model_pred = torch.stack(model_pred_list, dim=0)
                model_pred = model_pred.squeeze(2)
                model_pred = -model_pred  # Z-Image è¾“å‡ºå–è´Ÿ
                
                # è®¡ç®—é£æ ¼ç»“æ„ Loss
                loss, loss_components = loss_fn(
                    pred_v=model_pred,
                    target_v=target_velocity,
                    noisy_latents=noisy_latents,
                    timesteps=timesteps,
                    num_train_timesteps=1000,
                    return_components=True,
                )
                
                # åå‘ä¼ æ’­
                accelerator.backward(loss)
            
            # æ¢¯åº¦ç´¯ç§¯å®Œæˆåæ‰§è¡Œä¼˜åŒ–æ­¥éª¤
            if accelerator.sync_gradients:
                accelerator.clip_grad_norm_(trainable_params, args.max_grad_norm)
                optimizer.step()
                lr_scheduler.step()
                optimizer.zero_grad()
                
                progress_bar.update(1)
                global_step += 1
                
                # æ›´æ–° EMA loss
                current_loss = loss.item()
                if ema_loss is None:
                    ema_loss = current_loss
                else:
                    ema_loss = ema_decay * ema_loss + (1 - ema_decay) * current_loss
                
                current_lr = lr_scheduler.get_last_lr()[0]
                
                # æ‰“å°è¿›åº¦
                struct_l = loss_components["loss_struct"].item()
                light_l = loss_components["loss_light"].item()
                color_l = loss_components["loss_color"].item()
                tex_l = loss_components["loss_tex"].item()
                
                print(f"[STEP] {global_step}/{args.max_train_steps} epoch={epoch+1}/{args.num_train_epochs} "
                      f"loss={current_loss:.4f} ema={ema_loss:.4f} "
                      f"struct={struct_l:.4f} light={light_l:.4f} color={color_l:.4f} tex={tex_l:.4f} "
                      f"lr={current_lr:.2e}", flush=True)
            
            memory_optimizer.optimize_training_step()
                
        # Epoch ç»“æŸï¼Œä¿å­˜æ£€æŸ¥ç‚¹
        if (epoch + 1) % args.save_every_n_epochs == 0:
            save_path = Path(args.output_dir) / f"{args.output_name}_epoch{epoch+1}.safetensors"
            network.save_weights(save_path, dtype=weight_dtype)
            logger.info(f"\n[SAVE] ä¿å­˜æ£€æŸ¥ç‚¹ (Epoch {epoch+1}): {save_path}")
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_path = Path(args.output_dir) / f"{args.output_name}_final.safetensors"
    network.save_weights(final_path, dtype=weight_dtype)
    
    memory_optimizer.stop()
    
    logger.info("\n" + "="*60)
    logger.info(f"[OK] ç»“æ„é”é£æ ¼è¿ç§»è®­ç»ƒå®Œæˆï¼")
    logger.info(f"æœ€ç»ˆæ¨¡å‹: {final_path}")
    logger.info("="*60)


if __name__ == "__main__":
    main()

