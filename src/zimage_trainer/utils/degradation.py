# -*- coding: utf-8 -*-
"""
ğŸ”§ å›¾åƒé€€åŒ–æ¨¡å— (Image Degradation)

ç”¨äºå›¾ç”Ÿå›¾é£æ ¼è¿ç§»è®­ç»ƒçš„è‡ªç›‘ç£é€€åŒ–ç­–ç•¥

é€€åŒ–æµç¨‹ï¼š
1. Downsample: éšæœºç¼©å° (0.5x ~ 0.8x)
2. Blur: éšæœºé«˜æ–¯æ¨¡ç³Š (Kernel 3~7, Sigma 0.5~2.0)
3. Noise: å åŠ é«˜æ–¯ç™½å™ª (å¼ºåº¦ 0.02~0.05)
4. Upsample: åŒçº¿æ€§æ’å€¼å›åŸå°ºå¯¸
"""

import torch
import torch.nn.functional as F
import numpy as np
from typing import Tuple, Optional
import random


class ImageDegradation:
    """
    å›¾åƒé€€åŒ–å¤„ç†å™¨
    
    å°†é«˜æ¸…å›¾åƒé€€åŒ–ä¸ºä½è´¨é‡ç‰ˆæœ¬ï¼Œç”¨äºå›¾ç”Ÿå›¾è®­ç»ƒ
    """
    
    def __init__(
        self,
        downsample_range: Tuple[float, float] = (0.5, 0.8),
        blur_kernel_range: Tuple[int, int] = (3, 7),
        blur_sigma_range: Tuple[float, float] = (0.5, 2.0),
        noise_range: Tuple[float, float] = (0.02, 0.05),
        jpeg_quality_range: Optional[Tuple[int, int]] = None,  # å¯é€‰ JPEG å‹ç¼©
        enable_random: bool = True,  # éšæœºåŒ–å„é¡¹å‚æ•°
    ):
        self.downsample_range = downsample_range
        self.blur_kernel_range = blur_kernel_range
        self.blur_sigma_range = blur_sigma_range
        self.noise_range = noise_range
        self.jpeg_quality_range = jpeg_quality_range
        self.enable_random = enable_random
    
    def get_gaussian_kernel(
        self,
        kernel_size: int,
        sigma: float,
        device: torch.device,
        dtype: torch.dtype,
    ) -> torch.Tensor:
        """ç”Ÿæˆé«˜æ–¯æ¨¡ç³Šæ ¸"""
        coords = torch.arange(kernel_size, device=device, dtype=dtype) - kernel_size // 2
        g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))
        g = g / g.sum()
        kernel = g.outer(g)
        return kernel
    
    def gaussian_blur(
        self,
        image: torch.Tensor,
        kernel_size: int,
        sigma: float,
    ) -> torch.Tensor:
        """åº”ç”¨é«˜æ–¯æ¨¡ç³Š"""
        # ç¡®ä¿ kernel_size æ˜¯å¥‡æ•°
        if kernel_size % 2 == 0:
            kernel_size += 1
        
        kernel = self.get_gaussian_kernel(kernel_size, sigma, image.device, image.dtype)
        kernel = kernel.unsqueeze(0).unsqueeze(0)  # (1, 1, K, K)
        
        # å¯¹æ¯ä¸ªé€šé“åˆ†åˆ«æ¨¡ç³Š
        channels = image.shape[1]
        kernel = kernel.expand(channels, 1, -1, -1)
        
        padding = kernel_size // 2
        blurred = F.conv2d(image, kernel, padding=padding, groups=channels)
        return blurred
    
    def add_gaussian_noise(
        self,
        image: torch.Tensor,
        noise_level: float,
    ) -> torch.Tensor:
        """æ·»åŠ é«˜æ–¯å™ªå£°"""
        noise = torch.randn_like(image) * noise_level
        noisy = image + noise
        return noisy.clamp(0, 1)
    
    def downsample_upsample(
        self,
        image: torch.Tensor,
        scale: float,
    ) -> torch.Tensor:
        """é™é‡‡æ ·å†å‡é‡‡æ ·ï¼ˆæ¨¡æ‹Ÿåˆ†è¾¨ç‡æŸå¤±ï¼‰"""
        _, _, h, w = image.shape
        
        # é™é‡‡æ ·
        new_h = int(h * scale)
        new_w = int(w * scale)
        downsampled = F.interpolate(image, size=(new_h, new_w), mode='bilinear', align_corners=False)
        
        # å‡é‡‡æ ·å›åŸå°ºå¯¸
        upsampled = F.interpolate(downsampled, size=(h, w), mode='bilinear', align_corners=False)
        return upsampled
    
    def __call__(
        self,
        image: torch.Tensor,
        downsample_scale: Optional[float] = None,
        blur_kernel_size: Optional[int] = None,
        blur_sigma: Optional[float] = None,
        noise_level: Optional[float] = None,
    ) -> torch.Tensor:
        """
        åº”ç”¨é€€åŒ–å¤„ç†
        
        Args:
            image: (B, C, H, W) æˆ– (C, H, W)ï¼ŒèŒƒå›´ [0, 1]
            downsample_scale: é™é‡‡æ ·æ¯”ä¾‹ï¼ŒNone æ—¶éšæœº
            blur_kernel_size: æ¨¡ç³Šæ ¸å¤§å°ï¼ŒNone æ—¶éšæœº
            blur_sigma: æ¨¡ç³Š sigmaï¼ŒNone æ—¶éšæœº
            noise_level: å™ªå£°å¼ºåº¦ï¼ŒNone æ—¶éšæœº
            
        Returns:
            degraded: é€€åŒ–åçš„å›¾åƒ
        """
        # å¤„ç†ç»´åº¦
        squeeze = False
        if image.dim() == 3:
            image = image.unsqueeze(0)
            squeeze = True
        
        # éšæœºåŒ–å‚æ•°
        if self.enable_random:
            if downsample_scale is None:
                downsample_scale = random.uniform(*self.downsample_range)
            if blur_kernel_size is None:
                blur_kernel_size = random.choice(range(self.blur_kernel_range[0], self.blur_kernel_range[1] + 1, 2))
            if blur_sigma is None:
                blur_sigma = random.uniform(*self.blur_sigma_range)
            if noise_level is None:
                noise_level = random.uniform(*self.noise_range)
        else:
            # ä½¿ç”¨å›ºå®šä¸­å€¼
            if downsample_scale is None:
                downsample_scale = sum(self.downsample_range) / 2
            if blur_kernel_size is None:
                blur_kernel_size = self.blur_kernel_range[0] + (self.blur_kernel_range[1] - self.blur_kernel_range[0]) // 2
                if blur_kernel_size % 2 == 0:
                    blur_kernel_size += 1
            if blur_sigma is None:
                blur_sigma = sum(self.blur_sigma_range) / 2
            if noise_level is None:
                noise_level = sum(self.noise_range) / 2
        
        # 1. é™é‡‡æ ·-å‡é‡‡æ ·ï¼ˆæ¨¡æ‹Ÿåˆ†è¾¨ç‡æŸå¤±ï¼‰
        degraded = self.downsample_upsample(image, downsample_scale)
        
        # 2. é«˜æ–¯æ¨¡ç³Š
        degraded = self.gaussian_blur(degraded, blur_kernel_size, blur_sigma)
        
        # 3. æ·»åŠ å™ªå£°
        degraded = self.add_gaussian_noise(degraded, noise_level)
        
        if squeeze:
            degraded = degraded.squeeze(0)
        
        return degraded


class BatchDegradation:
    """
    æ‰¹é‡é€€åŒ–å¤„ç†å™¨
    
    ä¸º batch ä¸­çš„æ¯å¼ å›¾ç‰‡åº”ç”¨ä¸åŒçš„éšæœºé€€åŒ–å‚æ•°
    """
    
    def __init__(self, **kwargs):
        self.degradation = ImageDegradation(**kwargs)
    
    def __call__(self, images: torch.Tensor) -> torch.Tensor:
        """
        Args:
            images: (B, C, H, W) èŒƒå›´ [0, 1]
        Returns:
            degraded: (B, C, H, W) é€€åŒ–åçš„å›¾åƒ
        """
        batch_size = images.shape[0]
        degraded_list = []
        
        for i in range(batch_size):
            # æ¯å¼ å›¾ä½¿ç”¨ä¸åŒçš„éšæœºé€€åŒ–å‚æ•°
            degraded = self.degradation(images[i:i+1])
            degraded_list.append(degraded)
        
        return torch.cat(degraded_list, dim=0)


def create_degradation_transform(
    strength: str = "medium",
) -> ImageDegradation:
    """
    åˆ›å»ºé¢„è®¾çš„é€€åŒ–å˜æ¢
    
    Args:
        strength: "light" / "medium" / "heavy"
    """
    presets = {
        "light": {
            "downsample_range": (0.7, 0.9),
            "blur_kernel_range": (3, 5),
            "blur_sigma_range": (0.3, 1.0),
            "noise_range": (0.01, 0.03),
        },
        "medium": {
            "downsample_range": (0.5, 0.8),
            "blur_kernel_range": (3, 7),
            "blur_sigma_range": (0.5, 2.0),
            "noise_range": (0.02, 0.05),
        },
        "heavy": {
            "downsample_range": (0.3, 0.6),
            "blur_kernel_range": (5, 11),
            "blur_sigma_range": (1.0, 3.0),
            "noise_range": (0.04, 0.08),
        },
    }
    
    if strength not in presets:
        raise ValueError(f"Unknown strength: {strength}. Choose from {list(presets.keys())}")
    
    return ImageDegradation(**presets[strength])

