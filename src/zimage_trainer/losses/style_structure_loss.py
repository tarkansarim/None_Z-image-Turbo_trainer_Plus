# -*- coding: utf-8 -*-
"""
ğŸ¨ ç»“æ„é”é£æ ¼è¿ç§»æŸå¤±å‡½æ•° (Style-Structure Loss)

æ ¸å¿ƒç­–ç•¥ï¼š
- ç»“æ„é”å®š (SSIM)ï¼šé”æ­»è½®å»“ï¼Œé˜²æ­¢è„¸å´©
- å…‰å½±å­¦ä¹  (Lé€šé“ç»Ÿè®¡)ï¼šå­¦ä¹ å¤§å¸ˆçš„ S æ›²çº¿ã€å¯¹æ¯”åº¦
- è‰²è°ƒè¿ç§» (abé€šé“ç»Ÿè®¡)ï¼šå­¦ä¹ è‰²å½©åå¥½ï¼ˆå†·æš–/èƒ¶ç‰‡æ„Ÿï¼‰
- è´¨æ„Ÿå¢å¼º (é«˜é¢‘ L1)ï¼šå¢å¼ºæ¸…æ™°åº¦å’Œé¢—ç²’æ„Ÿ

æ•°å­¦å…¬å¼ï¼š
L_total = Î»_struct * L_SSIM + Î»_light * L_Moments_L + Î»_color * L_Moments_ab + Î»_tex * L_HighFreq

é€‚ç”¨åœºæ™¯ï¼š
- è¾“å…¥æ™®é€šç”»è´¨å›¾ç‰‡ï¼Œè¾“å‡ºå¤§å¸ˆçº§å…‰å½±ã€è‰²è°ƒå’Œçº¹ç†
- å›¾ç”Ÿå›¾é£æ ¼è¿ç§»è®­ç»ƒ
- ä¿æŒåŸå›¾å‡ ä½•ç»“æ„çš„åŒæ—¶å­¦ä¹ é£æ ¼
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Tuple, Dict, Optional
import logging

logger = logging.getLogger(__name__)


def rgb_to_lab(rgb: torch.Tensor) -> torch.Tensor:
    """
    RGB è½¬ Lab è‰²å½©ç©ºé—´
    
    Args:
        rgb: (B, 3, H, W) èŒƒå›´ [0, 1]
    Returns:
        lab: (B, 3, H, W) L:[0,100], a,b:[-128,127]
    """
    # ç¡®ä¿è¾“å…¥åœ¨ [0, 1] èŒƒå›´
    rgb = rgb.clamp(0, 1)
    
    # RGB to XYZ
    # sRGB åˆ°çº¿æ€§ RGB
    mask = rgb > 0.04045
    rgb_linear = torch.where(mask, ((rgb + 0.055) / 1.055) ** 2.4, rgb / 12.92)
    
    # å˜æ¢çŸ©é˜µ (sRGB D65)
    matrix = torch.tensor([
        [0.4124564, 0.3575761, 0.1804375],
        [0.2126729, 0.7151522, 0.0721750],
        [0.0193339, 0.1191920, 0.9503041]
    ], device=rgb.device, dtype=rgb.dtype)
    
    # (B, 3, H, W) -> (B, H, W, 3) -> matmul -> (B, H, W, 3) -> (B, 3, H, W)
    rgb_flat = rgb_linear.permute(0, 2, 3, 1)  # (B, H, W, 3)
    xyz = torch.matmul(rgb_flat, matrix.T)  # (B, H, W, 3)
    xyz = xyz.permute(0, 3, 1, 2)  # (B, 3, H, W)
    
    # XYZ to Lab
    # D65 ç™½ç‚¹
    xyz_ref = torch.tensor([0.95047, 1.0, 1.08883], device=rgb.device, dtype=rgb.dtype)
    xyz = xyz / xyz_ref.view(1, 3, 1, 1)
    
    # f(t) å‡½æ•°
    delta = 6.0 / 29.0
    mask = xyz > delta ** 3
    xyz_f = torch.where(mask, xyz ** (1/3), xyz / (3 * delta ** 2) + 4.0 / 29.0)
    
    # Lab
    L = 116.0 * xyz_f[:, 1:2] - 16.0
    a = 500.0 * (xyz_f[:, 0:1] - xyz_f[:, 1:2])
    b = 200.0 * (xyz_f[:, 1:2] - xyz_f[:, 2:3])
    
    lab = torch.cat([L, a, b], dim=1)
    return lab


def ssim(
    x: torch.Tensor,
    y: torch.Tensor,
    window_size: int = 11,
    size_average: bool = True,
    data_range: float = 1.0,
) -> torch.Tensor:
    """
    è®¡ç®— SSIM (Structural Similarity Index)
    
    Args:
        x, y: (B, C, H, W) è¾“å…¥å›¾åƒ
        window_size: æ»‘çª—å¤§å°
        size_average: æ˜¯å¦å–å¹³å‡
        data_range: æ•°æ®èŒƒå›´
    """
    C1 = (0.01 * data_range) ** 2
    C2 = (0.03 * data_range) ** 2
    
    # åˆ›å»ºé«˜æ–¯çª—å£
    sigma = 1.5
    coords = torch.arange(window_size, device=x.device, dtype=x.dtype) - window_size // 2
    g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))
    g = g / g.sum()
    window = g.outer(g)
    window = window.unsqueeze(0).unsqueeze(0)  # (1, 1, K, K)
    
    channels = x.shape[1]
    window = window.expand(channels, 1, window_size, window_size)
    
    # è®¡ç®—å‡å€¼
    mu_x = F.conv2d(x, window, padding=window_size // 2, groups=channels)
    mu_y = F.conv2d(y, window, padding=window_size // 2, groups=channels)
    
    mu_x_sq = mu_x ** 2
    mu_y_sq = mu_y ** 2
    mu_xy = mu_x * mu_y
    
    # è®¡ç®—æ–¹å·®å’Œåæ–¹å·®
    sigma_x_sq = F.conv2d(x ** 2, window, padding=window_size // 2, groups=channels) - mu_x_sq
    sigma_y_sq = F.conv2d(y ** 2, window, padding=window_size // 2, groups=channels) - mu_y_sq
    sigma_xy = F.conv2d(x * y, window, padding=window_size // 2, groups=channels) - mu_xy
    
    # SSIM
    ssim_map = ((2 * mu_xy + C1) * (2 * sigma_xy + C2)) / \
               ((mu_x_sq + mu_y_sq + C1) * (sigma_x_sq + sigma_y_sq + C2))
    
    if size_average:
        return ssim_map.mean()
    return ssim_map


class StyleStructureLoss(nn.Module):
    """
    ç»“æ„é”é£æ ¼è¿ç§»æŸå¤±å‡½æ•°
    
    è®¾è®¡ç†å¿µï¼š
    1. ç»“æ„é”å®šï¼šç”¨ SSIM é”æ­» L é€šé“è½®å»“ï¼Œé˜²æ­¢è„¸å´©
    2. å…‰å½±å­¦ä¹ ï¼šç”¨ L é€šé“ç»Ÿè®¡é‡ï¼ˆå‡å€¼+æ ‡å‡†å·®ï¼‰å­¦ä¹ å¤§å¸ˆçš„ S æ›²çº¿
    3. è‰²è°ƒè¿ç§»ï¼šç”¨ ab é€šé“ç»Ÿè®¡é‡å­¦ä¹ è‰²å½©åå¥½
    4. è´¨æ„Ÿå¢å¼ºï¼šç”¨é«˜é¢‘ L1 å¢å¼ºæ¸…æ™°åº¦
    """
    
    def __init__(
        self,
        lambda_struct: float = 1.0,      # ç»“æ„é”æƒé‡ (SSIM)
        lambda_light: float = 0.5,       # å…‰å½±å­¦ä¹ æƒé‡ (Lç»Ÿè®¡)
        lambda_color: float = 0.3,       # è‰²è°ƒè¿ç§»æƒé‡ (abç»Ÿè®¡)
        lambda_tex: float = 0.5,         # è´¨æ„Ÿå¢å¼ºæƒé‡ (é«˜é¢‘L1)
        lambda_base: float = 1.0,        # åŸºç¡€ v-prediction loss
        blur_kernel_size: int = 7,       # é«˜é¢‘æå–çš„æ¨¡ç³Šæ ¸å¤§å°
        ssim_window_size: int = 11,      # SSIM çª—å£å¤§å°
    ):
        super().__init__()
        self.lambda_struct = lambda_struct
        self.lambda_light = lambda_light
        self.lambda_color = lambda_color
        self.lambda_tex = lambda_tex
        self.lambda_base = lambda_base
        self.blur_kernel_size = blur_kernel_size
        self.ssim_window_size = ssim_window_size
        
        logger.info(f"[StyleStructureLoss] åˆå§‹åŒ–ç»“æ„é”é£æ ¼è¿ç§»æŸå¤±")
        logger.info(f"  ç»“æ„é” (SSIM): {lambda_struct}")
        logger.info(f"  å…‰å½±å­¦ä¹  (Lç»Ÿè®¡): {lambda_light}")
        logger.info(f"  è‰²è°ƒè¿ç§» (abç»Ÿè®¡): {lambda_color}")
        logger.info(f"  è´¨æ„Ÿå¢å¼º (é«˜é¢‘L1): {lambda_tex}")
    
    def get_gaussian_kernel(self, size: int, sigma: float = 1.5) -> torch.Tensor:
        """ç”Ÿæˆé«˜æ–¯æ¨¡ç³Šæ ¸"""
        coords = torch.arange(size) - size // 2
        g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))
        g = g / g.sum()
        kernel = g.outer(g)
        return kernel
    
    def gaussian_blur(self, x: torch.Tensor) -> torch.Tensor:
        """åº”ç”¨é«˜æ–¯æ¨¡ç³Š"""
        kernel = self.get_gaussian_kernel(self.blur_kernel_size).to(x.device, x.dtype)
        kernel = kernel.unsqueeze(0).unsqueeze(0)
        
        channels = x.shape[1]
        kernel = kernel.expand(channels, 1, -1, -1)
        
        padding = self.blur_kernel_size // 2
        blurred = F.conv2d(x, kernel, padding=padding, groups=channels)
        return blurred
    
    def get_high_freq(self, x: torch.Tensor) -> torch.Tensor:
        """æå–é«˜é¢‘åˆ†é‡"""
        low_freq = self.gaussian_blur(x)
        high_freq = x - low_freq
        return high_freq
    
    def compute_moments(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®ï¼ˆå…¨å±€ç»Ÿè®¡é‡ï¼‰"""
        # (B, C, H, W) -> å¯¹ H, W ç»´åº¦è®¡ç®—ç»Ÿè®¡é‡
        mean = x.mean(dim=[2, 3])  # (B, C)
        std = x.std(dim=[2, 3])    # (B, C)
        return mean, std
    
    def moments_loss(
        self,
        pred: torch.Tensor,
        target: torch.Tensor,
    ) -> torch.Tensor:
        """ç»Ÿè®¡é‡åŒ¹é…æŸå¤±"""
        pred_mean, pred_std = self.compute_moments(pred)
        target_mean, target_std = self.compute_moments(target)
        
        loss_mean = F.l1_loss(pred_mean, target_mean)
        loss_std = F.l1_loss(pred_std, target_std)
        
        return loss_mean + loss_std
    
    def forward(
        self,
        pred_v: torch.Tensor,
        target_v: torch.Tensor,
        pred_x0: torch.Tensor,
        target_x0: torch.Tensor,
        return_components: bool = False,
    ) -> torch.Tensor | Tuple[torch.Tensor, Dict[str, torch.Tensor]]:
        """
        è®¡ç®—ç»“æ„é”é£æ ¼è¿ç§»æŸå¤±
        
        Args:
            pred_v: æ¨¡å‹é¢„æµ‹çš„é€Ÿåº¦ v
            target_v: ç›®æ ‡é€Ÿåº¦ v
            pred_x0: é¢„æµ‹çš„å¹²å‡€ latent (éœ€è¦ VAE decode æˆ–è¿‘ä¼¼åˆ° RGB)
            target_x0: ç›®æ ‡å¹²å‡€ latent
            return_components: æ˜¯å¦è¿”å›å„åˆ†é‡
            
        Note:
            pred_x0/target_x0 åº”è¯¥æ˜¯ RGB å›¾åƒ (B, 3, H, W)ï¼ŒèŒƒå›´ [0, 1]
            å¦‚æœè¾“å…¥æ˜¯ latentï¼Œéœ€è¦å…ˆé€šè¿‡ VAE decode æˆ–è¿‘ä¼¼è½¬æ¢
        """
        # åŸºç¡€ v-prediction loss
        loss_base = F.mse_loss(pred_v, target_v)
        
        # è½¬æ¢åˆ° Lab ç©ºé—´
        pred_lab = rgb_to_lab(pred_x0)
        target_lab = rgb_to_lab(target_x0)
        
        # åˆ†ç¦» L å’Œ ab é€šé“
        pred_L = pred_lab[:, 0:1]      # (B, 1, H, W)
        target_L = target_lab[:, 0:1]
        pred_ab = pred_lab[:, 1:3]     # (B, 2, H, W)
        target_ab = target_lab[:, 1:3]
        
        # å½’ä¸€åŒ– L é€šé“ç”¨äº SSIM (0-100 -> 0-1)
        pred_L_norm = pred_L / 100.0
        target_L_norm = target_L / 100.0
        
        # 1. ç»“æ„é” (SSIM on L channel)
        ssim_val = ssim(pred_L_norm, target_L_norm, window_size=self.ssim_window_size)
        loss_struct = 1.0 - ssim_val  # SSIM è¶Šå¤§è¶Šå¥½ï¼Œæ‰€ä»¥å– 1-SSIM ä½œä¸º loss
        
        # 2. å…‰å½±å­¦ä¹  (L channel moments)
        loss_light = self.moments_loss(pred_L, target_L)
        
        # 3. è‰²è°ƒè¿ç§» (ab channel moments)
        loss_color = self.moments_loss(pred_ab, target_ab)
        
        # 4. è´¨æ„Ÿå¢å¼º (L channel high frequency)
        pred_high = self.get_high_freq(pred_L)
        target_high = self.get_high_freq(target_L)
        loss_tex = F.l1_loss(pred_high, target_high)
        
        # æ€»æŸå¤±
        total_loss = (
            self.lambda_base * loss_base +
            self.lambda_struct * loss_struct +
            self.lambda_light * loss_light +
            self.lambda_color * loss_color +
            self.lambda_tex * loss_tex
        )
        
        if return_components:
            components = {
                "loss_base": loss_base,
                "loss_struct": loss_struct,
                "loss_light": loss_light,
                "loss_color": loss_color,
                "loss_tex": loss_tex,
                "ssim": ssim_val,
                "total_loss": total_loss,
            }
            return total_loss, components
        
        return total_loss


class LatentStyleStructureLoss(StyleStructureLoss):
    """
    Latent ç©ºé—´çš„é£æ ¼ç»“æ„æŸå¤±
    
    åœ¨ Latent ç©ºé—´è¿‘ä¼¼è®¡ç®—ï¼Œé¿å… VAE decode çš„æ˜¾å­˜å¼€é”€
    
    è¿‘ä¼¼ç­–ç•¥ï¼š
    - Latent çš„ 4 ä¸ªé€šé“è¿‘ä¼¼å¯¹åº”ä¸åŒçš„è¯­ä¹‰ä¿¡æ¯
    - Channel 0 é€šå¸¸ä¸äº®åº¦ç›¸å…³
    - ä½¿ç”¨é™é‡‡æ ·-ä¸Šé‡‡æ ·æå–ä½é¢‘/é«˜é¢‘
    """
    
    def __init__(
        self,
        lambda_struct: float = 1.0,
        lambda_light: float = 0.5,
        lambda_color: float = 0.3,
        lambda_tex: float = 0.5,
        lambda_base: float = 1.0,
        downsample_factor: int = 4,
    ):
        super().__init__(
            lambda_struct=lambda_struct,
            lambda_light=lambda_light,
            lambda_color=lambda_color,
            lambda_tex=lambda_tex,
            lambda_base=lambda_base,
        )
        self.downsample_factor = downsample_factor
        logger.info(f"[LatentStyleStructureLoss] ä½¿ç”¨ Latent ç©ºé—´è¿‘ä¼¼è®¡ç®—")
    
    def get_low_freq_latent(self, x: torch.Tensor) -> torch.Tensor:
        """Latent ç©ºé—´ä½é¢‘æå–"""
        h, w = x.shape[-2:]
        target_h = max(1, h // self.downsample_factor)
        target_w = max(1, w // self.downsample_factor)
        
        x_small = F.adaptive_avg_pool2d(x, (target_h, target_w))
        x_low = F.interpolate(x_small, size=(h, w), mode='bilinear', align_corners=False)
        return x_low
    
    def forward(
        self,
        pred_v: torch.Tensor,
        target_v: torch.Tensor,
        noisy_latents: torch.Tensor,
        timesteps: torch.Tensor,
        num_train_timesteps: int = 1000,
        return_components: bool = False,
    ) -> torch.Tensor | Tuple[torch.Tensor, Dict[str, torch.Tensor]]:
        """
        åœ¨ Latent ç©ºé—´è®¡ç®—é£æ ¼ç»“æ„æŸå¤±
        
        Args:
            pred_v: æ¨¡å‹é¢„æµ‹çš„é€Ÿåº¦ v (B, C, H, W)
            target_v: ç›®æ ‡é€Ÿåº¦ v
            noisy_latents: åŠ å™ªåçš„ latents x_t
            timesteps: æ—¶é—´æ­¥
        """
        # åŸºç¡€ loss
        loss_base = F.mse_loss(pred_v, target_v)
        
        # è®¡ç®— sigma
        sigmas = timesteps.float() / num_train_timesteps
        sigma_broadcast = sigmas.view(-1, 1, 1, 1)
        
        # åæ¨ x0
        pred_x0 = noisy_latents - sigma_broadcast * pred_v
        target_x0 = noisy_latents - sigma_broadcast * target_v
        
        # åœ¨ Latent ç©ºé—´è¿‘ä¼¼è®¡ç®—
        # Channel 0 è¿‘ä¼¼äº®åº¦ï¼ŒChannel 1-3 è¿‘ä¼¼è‰²å½©
        pred_L = pred_x0[:, 0:1]
        target_L = target_x0[:, 0:1]
        pred_color = pred_x0[:, 1:4]
        target_color = target_x0[:, 1:4]
        
        # 1. ç»“æ„é” (Latent ç©ºé—´ SSIM è¿‘ä¼¼)
        # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è¿‘ä¼¼ç»“æ„ä¸€è‡´æ€§
        pred_L_flat = pred_L.view(pred_L.shape[0], -1)
        target_L_flat = target_L.view(target_L.shape[0], -1)
        cos_sim = F.cosine_similarity(pred_L_flat, target_L_flat, dim=1).mean()
        loss_struct = 1.0 - cos_sim
        
        # 2. å…‰å½±å­¦ä¹  (Channel 0 ç»Ÿè®¡é‡)
        loss_light = self.moments_loss(pred_L, target_L)
        
        # 3. è‰²è°ƒè¿ç§» (Channel 1-3 ç»Ÿè®¡é‡)
        loss_color = self.moments_loss(pred_color, target_color)
        
        # 4. è´¨æ„Ÿå¢å¼º (Channel 0 é«˜é¢‘)
        pred_low = self.get_low_freq_latent(pred_L)
        target_low = self.get_low_freq_latent(target_L)
        pred_high = pred_L - pred_low
        target_high = target_L - target_low
        loss_tex = F.l1_loss(pred_high, target_high)
        
        # æ€»æŸå¤±
        total_loss = (
            self.lambda_base * loss_base +
            self.lambda_struct * loss_struct +
            self.lambda_light * loss_light +
            self.lambda_color * loss_color +
            self.lambda_tex * loss_tex
        )
        
        if return_components:
            components = {
                "loss_base": loss_base,
                "loss_struct": loss_struct,
                "loss_light": loss_light,
                "loss_color": loss_color,
                "loss_tex": loss_tex,
                "cos_sim": cos_sim,
                "total_loss": total_loss,
            }
            return total_loss, components
        
        return total_loss

